{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "import re\n",
    "\n",
    "#To know more on feedparser https://www.pythonforbeginners.com/feedparser/using-feedparser-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return title and dictionary of word counts for an RSS feed\n",
    "def getwordcounts(url):\n",
    "    #parse the feed\n",
    "    d = feedparser.parse(url)\n",
    "    wc = {}\n",
    "    \n",
    "    #Loop over all the entries\n",
    "    for e in d.entries:\n",
    "        if 'summary' in e:\n",
    "            summary = e.summary\n",
    "        else:\n",
    "            summary = e.description\n",
    "        \n",
    "        # Extract a list of words\n",
    "        words = getwords(e.title + ' ' + summary)\n",
    "        \n",
    "        for word in words: \n",
    "            wc.setdefault(word, 0)\n",
    "            wc[word]+=1\n",
    "            \n",
    "    return (d.feed.title, wc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getwords(html):\n",
    "    #Remove all the HTML tags\n",
    "    txt = re.compile(r'<[^>]+>').sub('',html)\n",
    "    \n",
    "    #Split words by all non alpha characters\n",
    "    words = re.compile(r'[^A-Z^a-z]+').split(txt)\n",
    "    \n",
    "    #Convert to lowercase\n",
    "    return [word.lower() for word in words if word!='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to parse feed http://www.topix.com//rss/news/blogs\n",
      "\n",
      "Failed to parse feed http://gofugyourself.typepad.com/go_fug_yourself/index.rdf\n",
      "\n",
      "Failed to parse feed https://blog.zawodny.com/feed/\n",
      "\n",
      "Failed to parse feed http://scobleizer.wordpress.com/feed/\n",
      "\n",
      "Failed to parse feed http://www.456bereastreet.com/feed.xml\n",
      "\n",
      "Failed to parse feed http://feeds.dailykos.com/dailykos/index.xml\n",
      "\n",
      "Failed to parse feed http://www.huffingtonpost.com/raw_feed_index.rdf\n",
      "\n",
      "Failed to parse feed http://www.hyperorg.com/blogger/index.rdf\n",
      "\n",
      "Failed to parse feed http://xml.metafilter.com/rss.xml\n",
      "\n",
      "Failed to parse feed http://www.neilgaiman.com/journal/feed/rss.xml\n",
      "\n",
      "Failed to parse feed http://www.perezhilton.com/index.xml\n",
      "\n",
      "Failed to parse feed http://www.plasticbag.org/index.rdf\n",
      "\n",
      "Failed to parse feed http://feeds.feedburner.com/Spikedhumor\n",
      "\n",
      "Failed to parse feed http://www.techeblog.com/elephant/?mode=atom\n",
      "\n",
      "Failed to parse feed http://www.thesuperficial.com/feed\n",
      "\n",
      "Failed to parse feed http://feeds.gawker.com/gizmodo/full\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "apcount = {} #the number of blogs each word appeared in (apcount).\n",
    "wordcounts = {}\n",
    "\n",
    "feedlist = [line for line in open('feedlist.txt')]\n",
    "\n",
    "for feedurl in feedlist:\n",
    "    try : \n",
    "        title, wc = getwordcounts(feedurl)\n",
    "        wordcounts[title] = wc\n",
    "        for word, count in wc.items():\n",
    "            apcount.setdefault(word, 0)\n",
    "            if count > 1:\n",
    "                apcount[word]+=1\n",
    "    except:\n",
    "        print('Failed to parse feed %s' % feedurl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The next step is to generate the list of words that will actually be used in the counts for each blog.\n",
    "Since words like “the” will appear in almost all of them, and others like “flim-flam” might only appear in one,\n",
    "you can reduce the total number of words included by selecting only those words \n",
    "that are within maximum and minimum percentages. \n",
    "\n",
    "In this case, you can start with 10 percent as the lower bound and 50 percent as the upper bound,\n",
    "'''\n",
    "wordlist = []\n",
    "for w, bc in apcount.items():\n",
    "    frac = float(bc)/len(feedlist)\n",
    "    if frac > 0.2 and frac < 0.6: \n",
    "        wordlist.append(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The final step is to use the list of words and the list of blogs to create a text file \n",
    "containing a big matrix of all the word counts for each of the blogs. \n",
    "'''\n",
    "\n",
    "out = open('blogdata.txt', 'w')\n",
    "out.write('Blog')\n",
    "\n",
    "for word in wordlist: \n",
    "    out.write('\\t%s' % word)\n",
    "\n",
    "out.write('\\n')\n",
    "\n",
    "for blog, wc in wordcounts.items():\n",
    "    out.write(blog)\n",
    "    for word in wordlist:\n",
    "        if word in wc: \n",
    "            out.write('\\t%d' % wc[word])\n",
    "        else: \n",
    "            out.write('\\t0')\n",
    "    out.write('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
